{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a1613c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338a4476",
   "metadata": {},
   "source": [
    "## Generate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3770a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualOutcomes:\n",
    "    \n",
    "    def vision_list(self, df):\n",
    "        \"\"\"\n",
    "        Returns a list of visual acuity for patient.\n",
    "        Input: patient Pandas dataframe.\n",
    "        Output: list.\n",
    "        \"\"\"\n",
    "        df['CreatedDate'] = pd.to_datetime(df['CreatedDate'])\n",
    "        df.sort_values(by=['CreatedDate'], inplace=True)\n",
    "        lst = df['visual_acuity'].dropna()\n",
    "        return lst.to_list()\n",
    "    \n",
    "    def mean_vision(self, df):\n",
    "        \"\"\"\n",
    "        Returns the mean vision of a patient.\n",
    "        Input: patient Pandas dataframe.\n",
    "        Output: float (LogMAR letters).\n",
    "        \"\"\"\n",
    "        lst = self.vision_list(df)\n",
    "        return np.mean(lst)\n",
    "\n",
    "    def loss_from_peak(self, df):\n",
    "        \"\"\"\n",
    "        Returns the VLP for a patient.\n",
    "        Vision Loss from Peak (VLP) is defined as max vision minus last vision.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: float (LogMAR letters).\n",
    "        \"\"\"\n",
    "        visions = self.vision_list(df)\n",
    "        return max(visions) - visions[-1]\n",
    "    \n",
    "    def overall_visual_change(self, df):\n",
    "        \"\"\"\n",
    "        Returns the OVC for a patient.\n",
    "        Overall Visual Change (OVC) is defined as last vision minus first vision.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: float (LogMAR letters).\n",
    "        \"\"\"\n",
    "        visions = self.vision_list(df)\n",
    "        last = (visions[-1] + visions[-2] + visions[-3]) / 3\n",
    "        first = visions[0]\n",
    "        return last - first\n",
    "    \n",
    "    def peak_visual_improvement(self, df):\n",
    "        \"\"\"\n",
    "        Returns the PVI for a patient.\n",
    "        Peak Visual Improvement (PVI) is defined as max vision minus initial vision.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: float (LogMAR letters).\n",
    "        \"\"\"\n",
    "        visions = self.vision_list(df)\n",
    "        return max(visions) - visions[0]\n",
    "\n",
    "    def proportion_above_baseline(self, df):\n",
    "        \"\"\"\n",
    "        Returns the proportion of time above starting vision.\n",
    "        Input: patient Pandas dataframe.\n",
    "        Output: float (percentage).\n",
    "        \"\"\"\n",
    "        lst = self.vision_list(df)\n",
    "        starting_vision = lst[0]\n",
    "        above_lst = [i for i in lst if i > starting_vision]\n",
    "        if len(above_lst) != 0:\n",
    "            mean = sum(above_lst) / len(above_lst)\n",
    "        else:\n",
    "            mean = 0\n",
    "        return mean\n",
    "\n",
    "    def patient_clean(self, df, number_years):\n",
    "        \"\"\"\n",
    "        Shortens a patient's dataframe to x years after initiation.\n",
    "        Input: patient Pandas dataframe, integer.\n",
    "        Output: Pandas dataframe.\n",
    "        \"\"\"\n",
    "        dates = df['CreatedDate'].to_list()\n",
    "        first = dates[0]\n",
    "        cutoff = first.replace(year = first.year + number_years)\n",
    "        df = df[df['CreatedDate'] < cutoff]\n",
    "        return df\n",
    "\n",
    "    def time_above_baseline(self, df, number_years):\n",
    "        \"\"\"\n",
    "        Returns the number of days a patient spent above baseline in first x years.\n",
    "        Input: Pandas dataframe, integer.\n",
    "        Output: integer (days).\n",
    "        \"\"\"\n",
    "        df[\"CreatedDate\"] = pd.to_datetime(df[\"CreatedDate\"])\n",
    "        df.sort_values(by=['CreatedDate'], inplace=True)\n",
    "        dates = df[\"CreatedDate\"].to_list()\n",
    "        if (dates[-1] - dates[0]).days > (number_years * 365):\n",
    "            df = patient_clean(df, number_years)\n",
    "            vision = df['visual_acuity'].to_list()\n",
    "            dates2 = df[\"CreatedDate\"].to_list()\n",
    "            days = 0\n",
    "            starting_vision = vision[0]\n",
    "            for i in range(1, len(vision)):\n",
    "                if vision[i] > vision[0]:\n",
    "                    between = (dates2[i] - dates2[i-1]).days\n",
    "                    days += between\n",
    "            return days\n",
    "        else:\n",
    "            return 'nil'\n",
    "        \n",
    "    def time_above_baseline2(self, df):\n",
    "        \"\"\"\n",
    "        Returns the number of days a patient spent above baseline in first x years.\n",
    "        Input: Pandas dataframe, integer.\n",
    "        Output: integer (days).\n",
    "        \"\"\"\n",
    "        df[\"CreatedDate\"] = pd.to_datetime(df[\"CreatedDate\"])\n",
    "        df.sort_values(by=['CreatedDate'], inplace=True)\n",
    "        dates = df[\"CreatedDate\"].to_list()\n",
    "        vision = df['visual_acuity'].to_list()\n",
    "        dates2 = df[\"CreatedDate\"].to_list()\n",
    "        days = 0\n",
    "        starting_vision = vision[0]\n",
    "        for i in range(1, len(vision)):\n",
    "            if vision[i] > vision[0]:\n",
    "                between = (dates2[i] - dates2[i-1]).days\n",
    "                days += between\n",
    "        return days\n",
    "\n",
    "    def time_to_peak(self, df):\n",
    "        \"\"\"\n",
    "        Returns the TPVI for a patient.\n",
    "        Time to Peak Visual Improvement (TPVI) is defined in days.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: integer (days).\n",
    "        \"\"\"\n",
    "        df[\"CreatedDate\"] = pd.to_datetime(df[\"CreatedDate\"])\n",
    "        df.sort_values(by=['CreatedDate'], inplace=True)\n",
    "        dates = df[\"CreatedDate\"].to_list()\n",
    "        max_value = df['visual_acuity'].max()\n",
    "        df_fin = df[df['visual_acuity'] == max_value]\n",
    "        initial_date = dates[0]\n",
    "        final_date = df_fin.CreatedDate.iloc[0]\n",
    "        return (final_date - initial_date).days\n",
    "    \n",
    "    def baseline_vision(self, df):\n",
    "        \"\"\"\n",
    "        Returns the baseline vision for a patient.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: integer (LogMAR letters).\n",
    "        \"\"\"\n",
    "        lst = self.vision_list(df)\n",
    "        return lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ada3870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataframe(VisualOutcomes):\n",
    "    \n",
    "    def get_df(self):\n",
    "        \"\"\"\n",
    "        Returns the dataframe to be analysed (all visits).\n",
    "        \"\"\"\n",
    "        df = pd.read_csv('/home/jupyter/charliemacuject/pharma_reports/data/dme.csv')\n",
    "        df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def dataframe_gen(self, pdf, pat_id):\n",
    "        \"\"\"\n",
    "        Returns a dataframe of all adherence measures and visual outcomes.\n",
    "        For a singular patient only (will be one row).\n",
    "        Input: integer (patient id).\n",
    "        Output: Pandas dataframe.\n",
    "        \"\"\"\n",
    "        df = pdf[pdf[\"id\"] == pat_id]\n",
    "        data = {'mean_vision': [VisualOutcomes.mean_vision(self, df)], \n",
    "                'time_above_baseline': [VisualOutcomes.time_above_baseline2(self, df)],\n",
    "                'peak_visual_improvement': [VisualOutcomes.peak_visual_improvement(self, df)],\n",
    "                'overall_visual_change': [VisualOutcomes.overall_visual_change(self, df)],\n",
    "                'time_to_peak': [VisualOutcomes.time_to_peak(self, df)],\n",
    "                'baseline': [VisualOutcomes.baseline_vision(self, df)],\n",
    "                'visits': [len(df)]}\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    \n",
    "    def master_dataframe(self):\n",
    "        \"\"\"\n",
    "        Returns a dataframe of statics for all patients.\n",
    "        \"\"\"\n",
    "        df = self.get_df()\n",
    "        id_list = df[\"id\"].unique()\n",
    "        frames = []\n",
    "        for i in range(len(id_list)):\n",
    "            try:\n",
    "                pdf = self.dataframe_gen(df, id_list[i])\n",
    "                pdf['id'] = i\n",
    "                frames.append(pdf)\n",
    "            except:\n",
    "                i += 1\n",
    "        master = pd.concat(frames)\n",
    "        master.reset_index(inplace=True)\n",
    "        master.drop(columns=['index'], inplace=True)\n",
    "        return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0dcc8cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_vision</th>\n",
       "      <th>time_above_baseline</th>\n",
       "      <th>peak_visual_improvement</th>\n",
       "      <th>overall_visual_change</th>\n",
       "      <th>time_to_peak</th>\n",
       "      <th>baseline</th>\n",
       "      <th>visits</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.588235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.687500</td>\n",
       "      <td>54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>328</td>\n",
       "      <td>76.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.392857</td>\n",
       "      <td>1940</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>987</td>\n",
       "      <td>65.0</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.600000</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>363</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_vision  time_above_baseline  peak_visual_improvement  \\\n",
       "0    70.588235                    0                      0.0   \n",
       "1    71.687500                   54                      4.0   \n",
       "2    73.250000                    0                      0.0   \n",
       "3    75.392857                 1940                     20.0   \n",
       "4    75.600000                   50                      4.0   \n",
       "\n",
       "   overall_visual_change  time_to_peak  baseline  visits  id  \n",
       "0              -9.333333             0      76.0      34   0  \n",
       "1              -5.666667           328      76.0      18   1  \n",
       "2             -26.000000             0      85.0      32   2  \n",
       "3              15.000000           987      65.0      58   3  \n",
       "4              -4.000000           363      76.0      17   4  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = Dataframe()\n",
    "df = dataframe.master_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f7193a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827c33e",
   "metadata": {},
   "source": [
    "# Predict patient vision\n",
    "Goal: predict whether overall visual change (OVC, defined as last vision minus first vision) will be positive or negative for a given patient, using feature-engineered columns that summarise patient clinical history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a109141",
   "metadata": {},
   "source": [
    "First, we need to append a column to the dataframe that will determine whether OVC is positive or negative. To do this, we'll write a function to return a 1 or a 0 based on the value of OVC in that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5a3637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_ovc(row): return 1 if row['overall_visual_change'] > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc666858",
   "metadata": {},
   "source": [
    "Notice that the parameter being input to `label_ovc` is a Series object named row. Next, we use the `apply` function in Pandas to apply the function. We save the results in a new column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a0cd679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OVC_outcome'] = df.apply(lambda row: label_ovc(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e79ee1",
   "metadata": {},
   "source": [
    "Let's check that the new column is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c466733d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_vision</th>\n",
       "      <th>time_above_baseline</th>\n",
       "      <th>peak_visual_improvement</th>\n",
       "      <th>overall_visual_change</th>\n",
       "      <th>time_to_peak</th>\n",
       "      <th>baseline</th>\n",
       "      <th>visits</th>\n",
       "      <th>id</th>\n",
       "      <th>OVC_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.588235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.687500</td>\n",
       "      <td>54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>328</td>\n",
       "      <td>76.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.392857</td>\n",
       "      <td>1940</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>987</td>\n",
       "      <td>65.0</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.600000</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>363</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_vision  time_above_baseline  peak_visual_improvement  \\\n",
       "0    70.588235                    0                      0.0   \n",
       "1    71.687500                   54                      4.0   \n",
       "2    73.250000                    0                      0.0   \n",
       "3    75.392857                 1940                     20.0   \n",
       "4    75.600000                   50                      4.0   \n",
       "\n",
       "   overall_visual_change  time_to_peak  baseline  visits  id  OVC_outcome  \n",
       "0              -9.333333             0      76.0      34   0            0  \n",
       "1              -5.666667           328      76.0      18   1            0  \n",
       "2             -26.000000             0      85.0      32   2            0  \n",
       "3              15.000000           987      65.0      58   3            1  \n",
       "4              -4.000000           363      76.0      17   4            0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4654f",
   "metadata": {},
   "source": [
    "Finally, we'll save this amended dataframe so we don't have to run this every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "149ebabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/jupyter/charliemacuject/pharma_reports/data/dme_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9379796",
   "metadata": {},
   "source": [
    "## Baseline logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "43f6b345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.49%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "\n",
    "df = pd.read_csv('/home/jupyter/charliemacuject/pharma_reports/data/dme_features.csv')\n",
    "\n",
    "X = df.drop(columns=['overall_visual_change', 'OVC_outcome'])\n",
    "y = df.OVC_outcome\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "\n",
    "clf = linear_model.LogisticRegression(C=1e5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy: {}%\".format(np.round(100*score,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86240cc8",
   "metadata": {},
   "source": [
    "## Baseline XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f820af",
   "metadata": {},
   "source": [
    "We now need to save our features (`X`) and targets (`y`) by extracting them from the dataframe. Note that we need to drop `overall_visual_change` from the features as well as `OVC_outcome`, as we are classifying OVC rather than regressing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04830e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['overall_visual_change', 'OVC_outcome'])\n",
    "y = df.OVC_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4332e9c",
   "metadata": {},
   "source": [
    "Use scikit-learn to get our train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69c4cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1c0eb",
   "metadata": {},
   "source": [
    "We now create the XGBoost model using `XGBClassifier`. We don't actually need to specify the objective here, but it's good for clarity. If we had more than two classes, we would instead use `multi:softmax`, but we'll just use a regular logistic function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a5e688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', max_depth=6,\n",
    "                   learning_rate=0.1, n_estimators=100, random_state=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfbc44a",
   "metadata": {},
   "source": [
    "Call `fit` on the model to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f39cfc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:21:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=2,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0952dc3d",
   "metadata": {},
   "source": [
    "Get the predictions and store them. Let's see how accurate we are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e282eac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.09%\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy: {}%\".format(np.round(100*score,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e0cbd3",
   "metadata": {},
   "source": [
    "We achieve 76% accuracy with no hyperparameter tuning and minimal feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28253e",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c7ecc",
   "metadata": {},
   "source": [
    "Using a baseline score of 76%, we will see if we can improve upon the classifier using hyperparameter tuning. However, we'll use cross validation accuracy this time to allow us to perform grid searches and random searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ae8e998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  [0.78 0.78 0.78 0.75 0.83]\n",
      "Accuracy mean: 0.78\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['overall_visual_change', 'OVC_outcome'])\n",
    "y = df.OVC_outcome\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2,\n",
    "                   verbosity=0)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(xgb, X, y, cv=5)\n",
    "print(\"Accuracy: \", np.round(scores, 2))\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3c335",
   "metadata": {},
   "source": [
    "When fine-tuning hyperparameters, `GridSearchCV` and `RandomizedSearchCV` are the main options. However, we need to ensure that cross-validation and the searches split the data the same way. Thus, we use stratified k-fold, which includes the same percentage of target values in each fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d17edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c2cddc",
   "metadata": {},
   "source": [
    "The `kfold` variable can now be used inside `cross_val_score` and the search functions to ensure consistent results. We'll now redo our baseline using `kfold` so we can appropriately compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2134adfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.81 0.75 0.92 0.72 0.75]\n",
      "Accuracy mean: 0.79\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgb, X, y, cv=kfold)\n",
    "print('Accuracy:', np.round(scores, 2))\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452fc28d",
   "metadata": {},
   "source": [
    "`GridSearchCV` searches all possible combinations in a hyperparameter grid to find the best results. `RandomizedSearchCV` selects 10 random hyperparameter combinations to search, which makes it computationally less expensive than grid search.\n",
    "\n",
    "We'll write a function that can swap between applying grid search and random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3d7941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def grid_search(params, random=False):\n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic',\n",
    "                       random_state=2, verbosity=0)\n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=20, n_jobs=-1)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    grid.fit(X,y)\n",
    "    best_params = grid.best_params_\n",
    "    print(\"Best params: \", best_params)\n",
    "    best_score = grid.best_score_\n",
    "    print(\"Training score: {:.3f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32fb269",
   "metadata": {},
   "source": [
    "There are many, many hyperparameters we could tune (see the XGBoost documentation [here](https://xgboost.readthedocs.io/en/latest/parameter.html)). We'll choose the key ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fcd7941c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'n_estimators': 200}\n",
      "Training score: 0.801\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators':[100, 200, 400, 800]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e638db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'learning_rate': 0.05}\n",
      "Training score: 0.801\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc49e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'max_depth':[2, 3, 5, 6, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f32b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'gamma':[0, 0.1, 0.5, 1, 2, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae473622",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'min_child_weight':[1, 2, 3, 4, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd271ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'colsample_bytree':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306a9f9",
   "metadata": {},
   "source": [
    "### Early stopping\n",
    "Early stopping allows us to choose the number of training rounds without predefining it. Instead, we continue to train until no further gains are produced. A score is determined after each boosting round, and a peak score is achieved when all subsequent scores fail to produce any gains. We choose the number of rounds after peak to examine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0aaefd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.21739\n",
      "[1]\tvalidation_0-error:0.17391\n",
      "[2]\tvalidation_0-error:0.19565\n",
      "[3]\tvalidation_0-error:0.23913\n",
      "[4]\tvalidation_0-error:0.26087\n",
      "[5]\tvalidation_0-error:0.26087\n",
      "[6]\tvalidation_0-error:0.26087\n",
      "[7]\tvalidation_0-error:0.26087\n",
      "[8]\tvalidation_0-error:0.23913\n",
      "[9]\tvalidation_0-error:0.23913\n",
      "[10]\tvalidation_0-error:0.26087\n",
      "Accuracy: 82.61%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric='error'\n",
    "model.fit(X_train, y_train, eval_metric=\"error\", eval_set=eval_set, early_stopping_rounds=10, \n",
    "          verbose=True)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1aed4e",
   "metadata": {},
   "source": [
    "Early stopping reveals that `n_estimators = 2` gives the best result. We try again, but using a maximum of 5000 trees and 100 consecutive rounds of non-improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d28e44aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.61%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=2, n_estimators=5000)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric=\"error\"\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, \n",
    "          early_stopping_rounds=100, verbose=False)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4036c4d1",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22acec88",
   "metadata": {},
   "source": [
    "Instead of using a normal decision tree, we can bag predictors using the following procedure:\n",
    "1. Randomly choose a subset of features (\"bootstap replicates of learning set\").\n",
    "2. Train a model using this subset.\n",
    "3. Save that model, and repeat step 1.\n",
    "4. Using these various trained models, make a prediction, and take the average.\n",
    "\n",
    "This procedure is known as _bagging_. The intuition behind it is this: although each of the models trained on a subset of data will make more errors than a model trained on the full dataset, those errors will not be correlated with each other. The average of errors is thus zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7bbc10e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'mean_vision', 'time_above_baseline',\n",
       "       'peak_visual_improvement', 'overall_visual_change', 'time_to_peak',\n",
       "       'baseline', 'visits', 'id', 'OVC_outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "df = pd.read_csv('/home/jupyter/charliemacuject/pharma_reports/data/dme_features.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d9017",
   "metadata": {},
   "source": [
    "Set the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd456103",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Unnamed: 0', 'OVC_outcome', 'overall_visual_change'])\n",
    "y = df.OVC_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87e93c0",
   "metadata": {},
   "source": [
    "We create a random forest by specifying parameters that indicate how many trees should be in the forest, how we should subset the data items (the rows) and how we should subset the fields (the columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49e81dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(xs, y, n_estimators=40, max_samples=135,\n",
    "      max_features=0.5, min_samples_leaf=5, **kwargs):\n",
    "    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n",
    "                                max_samples=max_samples, max_features=max_features,\n",
    "                                min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd9ba2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9288f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_print(m, X_train, y_train, X_test, y_test): \n",
    "    train_score = accuracy_score(m.predict(X_train), y_train)\n",
    "    test_score = accuracy_score(m.predict(X_test), y_test)\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "daf21505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8888888888888888, 0.7608695652173914)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = rf(X_train, y_train);\n",
    "accuracy_print(m, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052e5c3",
   "metadata": {},
   "source": [
    "We want to be able to see how this model is making its predictions using _feature importance_. We can grab this using an sklearn built in attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6258586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b06c5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peak_visual_improvement</td>\n",
       "      <td>0.288687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_above_baseline</td>\n",
       "      <td>0.212206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_to_peak</td>\n",
       "      <td>0.205339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_vision</td>\n",
       "      <td>0.103845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.073018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>visits</td>\n",
       "      <td>0.071823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id</td>\n",
       "      <td>0.045083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      cols       imp\n",
       "2  peak_visual_improvement  0.288687\n",
       "1      time_above_baseline  0.212206\n",
       "3             time_to_peak  0.205339\n",
       "0              mean_vision  0.103845\n",
       "4                 baseline  0.073018\n",
       "5                   visits  0.071823\n",
       "6                       id  0.045083"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = rf_feat_importance(m, X_train)\n",
    "fi[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d541b58",
   "metadata": {},
   "source": [
    "We'd like to understand the relationship between predictors and OVC. It's a good idea to first check the distribution of important predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d914aab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = X_train.peak_visual_improvement.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccf053",
   "metadata": {},
   "source": [
    "We now examine _partial dependence plots_. The question we are asking is: if a row varied on nothing other than the feature in question, how would it impact the dependent variable? In other words, how does `peak_visual_improvement` impact sales price, all other things being equal?\n",
    "\n",
    "We can't just take an average to answer this question. This is because other things vary from patient to patient, not just their PVIs. This approach would instead capture the effect of how every other field changed along with PVI and how that overall change affected OVC.\n",
    "\n",
    "Instead, what we do is replace every single value in the PVI column with 0, and then calculate the predicted OVC, and then average. Then we do the same for PVI = 1.0, 2.0 and so on. This isolates the effect of only PVI.\n",
    "\n",
    "With these averages, we can then plot each of these years on the x-axis, and each of the predictions on the y-axis. This is a partial dependence plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c652af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(12,4))\n",
    "#plot_partial_dependence(m, df, ['peak_visual_improvement', 'overall_visual_change'],\n",
    "                       #grid_resolution=20, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8b45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
