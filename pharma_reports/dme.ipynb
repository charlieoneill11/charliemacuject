{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "406b40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027ec8d6",
   "metadata": {},
   "source": [
    "## Generate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff2318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualOutcomes:\n",
    "    \n",
    "    def vision_list(self, df):\n",
    "        \"\"\"\n",
    "        Returns a list of visual acuity for patient.\n",
    "        Input: patient Pandas dataframe.\n",
    "        Output: list.\n",
    "        \"\"\"\n",
    "        df['CreatedDate'] = pd.to_datetime(df['CreatedDate'])\n",
    "        df.sort_values(by=['CreatedDate'], inplace=True)\n",
    "        lst = df['visual_acuity'].dropna()\n",
    "        return lst.to_list()\n",
    "    \n",
    "    def mean_vision(self, df):\n",
    "        \"\"\"\n",
    "        Returns the mean vision of a patient.\n",
    "        Input: patient Pandas dataframe.\n",
    "        Output: float (LogMAR letters).\n",
    "        \"\"\"\n",
    "        lst = self.vision_list(df)\n",
    "        return np.mean(lst)\n",
    "\n",
    "    def loss_from_peak(self, df):\n",
    "        \"\"\"\n",
    "        Returns the VLP for a patient.\n",
    "        Vision Loss from Peak (VLP) is defined as max vision minus last vision.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: float (LogMAR letters).\n",
    "        \"\"\"\n",
    "        visions = self.vision_list(df)\n",
    "        return max(visions) - visions[-1]\n",
    "    \n",
    "    def overall_visual_change(self, df):\n",
    "        \"\"\"\n",
    "        Returns the OVC for a patient.\n",
    "        Overall Visual Change (OVC) is defined as last vision minus first vision.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: float (LogMAR letters).\n",
    "        \"\"\"\n",
    "        visions = self.vision_list(df)\n",
    "        last = (visions[-1] + visions[-2] + visions[-3]) / 3\n",
    "        first = visions[0]\n",
    "        return last - first\n",
    "    \n",
    "    def peak_visual_improvement(self, df):\n",
    "        \"\"\"\n",
    "        Returns the PVI for a patient.\n",
    "        Peak Visual Improvement (PVI) is defined as max vision minus initial vision.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: float (LogMAR letters).\n",
    "        \"\"\"\n",
    "        visions = self.vision_list(df)\n",
    "        return max(visions) - visions[0]\n",
    "\n",
    "    def proportion_above_baseline(self, df):\n",
    "        \"\"\"\n",
    "        Returns the proportion of time above starting vision.\n",
    "        Input: patient Pandas dataframe.\n",
    "        Output: float (percentage).\n",
    "        \"\"\"\n",
    "        lst = self.vision_list(df)\n",
    "        starting_vision = lst[0]\n",
    "        above_lst = [i for i in lst if i > starting_vision]\n",
    "        if len(above_lst) != 0:\n",
    "            mean = sum(above_lst) / len(above_lst)\n",
    "        else:\n",
    "            mean = 0\n",
    "        return mean\n",
    "\n",
    "    def patient_clean(self, df, number_years):\n",
    "        \"\"\"\n",
    "        Shortens a patient's dataframe to x years after initiation.\n",
    "        Input: patient Pandas dataframe, integer.\n",
    "        Output: Pandas dataframe.\n",
    "        \"\"\"\n",
    "        dates = df['CreatedDate'].to_list()\n",
    "        first = dates[0]\n",
    "        cutoff = first.replace(year = first.year + number_years)\n",
    "        df = df[df['CreatedDate'] < cutoff]\n",
    "        return df\n",
    "\n",
    "    def time_above_baseline(self, df, number_years):\n",
    "        \"\"\"\n",
    "        Returns the number of days a patient spent above baseline in first x years.\n",
    "        Input: Pandas dataframe, integer.\n",
    "        Output: integer (days).\n",
    "        \"\"\"\n",
    "        df[\"CreatedDate\"] = pd.to_datetime(df[\"CreatedDate\"])\n",
    "        df.sort_values(by=['CreatedDate'], inplace=True)\n",
    "        dates = df[\"CreatedDate\"].to_list()\n",
    "        if (dates[-1] - dates[0]).days > (number_years * 365):\n",
    "            df = patient_clean(df, number_years)\n",
    "            vision = df['visual_acuity'].to_list()\n",
    "            dates2 = df[\"CreatedDate\"].to_list()\n",
    "            days = 0\n",
    "            starting_vision = vision[0]\n",
    "            for i in range(1, len(vision)):\n",
    "                if vision[i] > vision[0]:\n",
    "                    between = (dates2[i] - dates2[i-1]).days\n",
    "                    days += between\n",
    "            return days\n",
    "        else:\n",
    "            return 'nil'\n",
    "        \n",
    "    def time_above_baseline2(self, df):\n",
    "        \"\"\"\n",
    "        Returns the number of days a patient spent above baseline in first x years.\n",
    "        Input: Pandas dataframe, integer.\n",
    "        Output: integer (days).\n",
    "        \"\"\"\n",
    "        df[\"CreatedDate\"] = pd.to_datetime(df[\"CreatedDate\"])\n",
    "        df.sort_values(by=['CreatedDate'], inplace=True)\n",
    "        dates = df[\"CreatedDate\"].to_list()\n",
    "        vision = df['visual_acuity'].to_list()\n",
    "        dates2 = df[\"CreatedDate\"].to_list()\n",
    "        days = 0\n",
    "        starting_vision = vision[0]\n",
    "        for i in range(1, len(vision)):\n",
    "            if vision[i] > vision[0]:\n",
    "                between = (dates2[i] - dates2[i-1]).days\n",
    "                days += between\n",
    "        return days\n",
    "\n",
    "    def time_to_peak(self, df):\n",
    "        \"\"\"\n",
    "        Returns the TPVI for a patient.\n",
    "        Time to Peak Visual Improvement (TPVI) is defined in days.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: integer (days).\n",
    "        \"\"\"\n",
    "        df[\"CreatedDate\"] = pd.to_datetime(df[\"CreatedDate\"])\n",
    "        df.sort_values(by=['CreatedDate'], inplace=True)\n",
    "        dates = df[\"CreatedDate\"].to_list()\n",
    "        max_value = df['visual_acuity'].max()\n",
    "        df_fin = df[df['visual_acuity'] == max_value]\n",
    "        initial_date = dates[0]\n",
    "        final_date = df_fin.CreatedDate.iloc[0]\n",
    "        return (final_date - initial_date).days\n",
    "    \n",
    "    def baseline_vision(self, df):\n",
    "        \"\"\"\n",
    "        Returns the baseline vision for a patient.\n",
    "        Input: Pandas dataframe.\n",
    "        Output: integer (LogMAR letters).\n",
    "        \"\"\"\n",
    "        lst = self.vision_list(df)\n",
    "        return lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddfcd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataframe(VisualOutcomes):\n",
    "    \n",
    "    def get_df(self):\n",
    "        \"\"\"\n",
    "        Returns the dataframe to be analysed (all visits).\n",
    "        \"\"\"\n",
    "        df = pd.read_csv('/home/jupyter/charliemacuject/pharma_reports/data/dme.csv')\n",
    "        df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def dataframe_gen(self, pdf, pat_id):\n",
    "        \"\"\"\n",
    "        Returns a dataframe of all adherence measures and visual outcomes.\n",
    "        For a singular patient only (will be one row).\n",
    "        Input: integer (patient id).\n",
    "        Output: Pandas dataframe.\n",
    "        \"\"\"\n",
    "        df = pdf[pdf[\"id\"] == pat_id]\n",
    "        data = {'mean_vision': [VisualOutcomes.mean_vision(self, df)], \n",
    "                'time_above_baseline': [VisualOutcomes.time_above_baseline2(self, df)],\n",
    "                'peak_visual_improvement': [VisualOutcomes.peak_visual_improvement(self, df)],\n",
    "                'overall_visual_change': [VisualOutcomes.overall_visual_change(self, df)],\n",
    "                'time_to_peak': [VisualOutcomes.time_to_peak(self, df)],\n",
    "                'baseline': [VisualOutcomes.baseline_vision(self, df)],\n",
    "                'visits': [len(df)]}\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    \n",
    "    def master_dataframe(self):\n",
    "        \"\"\"\n",
    "        Returns a dataframe of statics for all patients.\n",
    "        \"\"\"\n",
    "        df = self.get_df()\n",
    "        id_list = df[\"id\"].unique()\n",
    "        frames = []\n",
    "        for i in range(len(id_list)):\n",
    "            try:\n",
    "                pdf = self.dataframe_gen(df, id_list[i])\n",
    "                pdf['id'] = i\n",
    "                frames.append(pdf)\n",
    "            except:\n",
    "                i += 1\n",
    "        master = pd.concat(frames)\n",
    "        master.reset_index(inplace=True)\n",
    "        master.drop(columns=['index'], inplace=True)\n",
    "        return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52f6c1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_vision</th>\n",
       "      <th>time_above_baseline</th>\n",
       "      <th>peak_visual_improvement</th>\n",
       "      <th>overall_visual_change</th>\n",
       "      <th>time_to_peak</th>\n",
       "      <th>baseline</th>\n",
       "      <th>visits</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.588235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.687500</td>\n",
       "      <td>54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>328</td>\n",
       "      <td>76.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.392857</td>\n",
       "      <td>1940</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>987</td>\n",
       "      <td>65.0</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.600000</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>363</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_vision  time_above_baseline  peak_visual_improvement  \\\n",
       "0    70.588235                    0                      0.0   \n",
       "1    71.687500                   54                      4.0   \n",
       "2    73.250000                    0                      0.0   \n",
       "3    75.392857                 1940                     20.0   \n",
       "4    75.600000                   50                      4.0   \n",
       "\n",
       "   overall_visual_change  time_to_peak  baseline  visits  id  \n",
       "0              -9.333333             0      76.0      34   0  \n",
       "1              -5.666667           328      76.0      18   1  \n",
       "2             -26.000000             0      85.0      32   2  \n",
       "3              15.000000           987      65.0      58   3  \n",
       "4              -4.000000           363      76.0      17   4  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = Dataframe()\n",
    "df = dataframe.master_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47508d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a557c",
   "metadata": {},
   "source": [
    "# Predict patient vision\n",
    "Goal: predict whether overall visual change (OVC, defined as last vision minus first vision) will be positive or negative for a given patient, using feature-engineered columns that summarise patient clinical history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b2af0",
   "metadata": {},
   "source": [
    "First, we need to append a column to the dataframe that will determine whether OVC is positive or negative. To do this, we'll write a function to return a 1 or a 0 based on the value of OVC in that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b385171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_ovc(row): return 1 if row['overall_visual_change'] > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2325c4cc",
   "metadata": {},
   "source": [
    "Notice that the parameter being input to `label_ovc` is a Series object named row. Next, we use the `apply` function in Pandas to apply the function. We save the results in a new column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e39ce4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OVC_outcome'] = df.apply(lambda row: label_ovc(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba467f",
   "metadata": {},
   "source": [
    "Let's check that the new column is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0cd4b376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_vision</th>\n",
       "      <th>time_above_baseline</th>\n",
       "      <th>peak_visual_improvement</th>\n",
       "      <th>overall_visual_change</th>\n",
       "      <th>time_to_peak</th>\n",
       "      <th>baseline</th>\n",
       "      <th>visits</th>\n",
       "      <th>id</th>\n",
       "      <th>OVC_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.588235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.687500</td>\n",
       "      <td>54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>328</td>\n",
       "      <td>76.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.392857</td>\n",
       "      <td>1940</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>987</td>\n",
       "      <td>65.0</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.600000</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>363</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_vision  time_above_baseline  peak_visual_improvement  \\\n",
       "0    70.588235                    0                      0.0   \n",
       "1    71.687500                   54                      4.0   \n",
       "2    73.250000                    0                      0.0   \n",
       "3    75.392857                 1940                     20.0   \n",
       "4    75.600000                   50                      4.0   \n",
       "\n",
       "   overall_visual_change  time_to_peak  baseline  visits  id  OVC_outcome  \n",
       "0              -9.333333             0      76.0      34   0            0  \n",
       "1              -5.666667           328      76.0      18   1            0  \n",
       "2             -26.000000             0      85.0      32   2            0  \n",
       "3              15.000000           987      65.0      58   3            1  \n",
       "4              -4.000000           363      76.0      17   4            0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb705aa",
   "metadata": {},
   "source": [
    "Finally, we'll save this amended dataframe so we don't have to run this every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e20e72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/jupyter/charliemacuject/pharma_reports/data/dme_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7de4c",
   "metadata": {},
   "source": [
    "## Baseline logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7703ba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.49%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "\n",
    "df = pd.read_csv('/home/jupyter/charliemacuject/pharma_reports/data/dme_features.csv')\n",
    "\n",
    "X = df.drop(columns=['overall_visual_change', 'OVC_outcome'])\n",
    "y = df.OVC_outcome\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "\n",
    "clf = linear_model.LogisticRegression(C=1e5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy: {}%\".format(np.round(100*score,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d753eb5",
   "metadata": {},
   "source": [
    "## Baseline XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b62da",
   "metadata": {},
   "source": [
    "We now need to save our features (`X`) and targets (`y`) by extracting them from the dataframe. Note that we need to drop `overall_visual_change` from the features as well as `OVC_outcome`, as we are classifying OVC rather than regressing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02b14b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['overall_visual_change', 'OVC_outcome'])\n",
    "y = df.OVC_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5418f1c5",
   "metadata": {},
   "source": [
    "Use scikit-learn to get our train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6dd66d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994085bb",
   "metadata": {},
   "source": [
    "We now create the XGBoost model using `XGBClassifier`. We don't actually need to specify the objective here, but it's good for clarity. If we had more than two classes, we would instead use `multi:softmax`, but we'll just use a regular logistic function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbdbd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', max_depth=6,\n",
    "                   learning_rate=0.1, n_estimators=100, random_state=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d199a4",
   "metadata": {},
   "source": [
    "Call `fit` on the model to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96e96a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:21:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=2,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5079d0",
   "metadata": {},
   "source": [
    "Get the predictions and store them. Let's see how accurate we are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63de6977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.09%\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy: {}%\".format(np.round(100*score,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95856c4",
   "metadata": {},
   "source": [
    "We achieve 76% accuracy with no hyperparameter tuning and minimal feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d192d8",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b05720",
   "metadata": {},
   "source": [
    "Using a baseline score of 76%, we will see if we can improve upon the classifier using hyperparameter tuning. However, we'll use cross validation accuracy this time to allow us to perform grid searches and random searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "937cf06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  [0.78 0.78 0.78 0.75 0.83]\n",
      "Accuracy mean: 0.78\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['overall_visual_change', 'OVC_outcome'])\n",
    "y = df.OVC_outcome\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2,\n",
    "                   verbosity=0)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(xgb, X, y, cv=5)\n",
    "print(\"Accuracy: \", np.round(scores, 2))\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d819dad",
   "metadata": {},
   "source": [
    "When fine-tuning hyperparameters, `GridSearchCV` and `RandomizedSearchCV` are the main options. However, we need to ensure that cross-validation and the searches split the data the same way. Thus, we use stratified k-fold, which includes the same percentage of target values in each fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e28818ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f112e1",
   "metadata": {},
   "source": [
    "The `kfold` variable can now be used inside `cross_val_score` and the search functions to ensure consistent results. We'll now redo our baseline using `kfold` so we can appropriately compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91cd65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.81 0.75 0.92 0.72 0.75]\n",
      "Accuracy mean: 0.79\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgb, X, y, cv=kfold)\n",
    "print('Accuracy:', np.round(scores, 2))\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bc0bd7",
   "metadata": {},
   "source": [
    "`GridSearchCV` searches all possible combinations in a hyperparameter grid to find the best results. `RandomizedSearchCV` selects 10 random hyperparameter combinations to search, which makes it computationally less expensive than grid search.\n",
    "\n",
    "We'll write a function that can swap between applying grid search and random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d07a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def grid_search(params, random=False):\n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic',\n",
    "                       random_state=2, verbosity=0)\n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=20, n_jobs=-1)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    grid.fit(X,y)\n",
    "    best_params = grid.best_params_\n",
    "    print(\"Best params: \", best_params)\n",
    "    best_score = grid.best_score_\n",
    "    print(\"Training score: {:.3f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e8738",
   "metadata": {},
   "source": [
    "There are many, many hyperparameters we could tune (see the XGBoost documentation [here](https://xgboost.readthedocs.io/en/latest/parameter.html)). We'll choose the key ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "949b1e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'n_estimators': 200}\n",
      "Training score: 0.801\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators':[100, 200, 400, 800]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74f64735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'learning_rate': 0.05}\n",
      "Training score: 0.801\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'max_depth':[2, 3, 5, 6, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04743c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'gamma':[0, 0.1, 0.5, 1, 2, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'min_child_weight':[1, 2, 3, 4, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'colsample_bytree':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed62e26",
   "metadata": {},
   "source": [
    "### Early stopping\n",
    "Early stopping allows us to choose the number of training rounds without predefining it. Instead, we continue to train until no further gains are produced. A score is determined after each boosting round, and a peak score is achieved when all subsequent scores fail to produce any gains. We choose the number of rounds after peak to examine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4504485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.21739\n",
      "[1]\tvalidation_0-error:0.17391\n",
      "[2]\tvalidation_0-error:0.19565\n",
      "[3]\tvalidation_0-error:0.23913\n",
      "[4]\tvalidation_0-error:0.26087\n",
      "[5]\tvalidation_0-error:0.26087\n",
      "[6]\tvalidation_0-error:0.26087\n",
      "[7]\tvalidation_0-error:0.26087\n",
      "[8]\tvalidation_0-error:0.23913\n",
      "[9]\tvalidation_0-error:0.23913\n",
      "[10]\tvalidation_0-error:0.26087\n",
      "Accuracy: 82.61%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric='error'\n",
    "model.fit(X_train, y_train, eval_metric=\"error\", eval_set=eval_set, early_stopping_rounds=10, \n",
    "          verbose=True)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e90859",
   "metadata": {},
   "source": [
    "Early stopping reveals that `n_estimators = 2` gives the best result. We try again, but using a maximum of 5000 trees and 100 consecutive rounds of non-improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "154370d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.61%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=2, n_estimators=5000)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric=\"error\"\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, \n",
    "          early_stopping_rounds=100, verbose=False)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a12b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
